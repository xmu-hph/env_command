# 总结
非常奇怪，玻尔兹曼机真的是机器学习的起源，就神奇。诺贝尔物理学奖的评审好像还真是有点刷子。

`Hopfield`网络典型的操作是内置一个对阵矩阵`W`，然后对输入的向量反复做矩阵映射，直到稳定。得到的就是输入向量在已知的向量几何中最接近的向量。缺点在于可存储的模式向量数量不多。这个网络的典型思想就是通过函数变换成另一个向量。是人工智能中的一大思路出发点。

`Boltzmann Machine`网络典型的操作就是根据训练数据学习神经网络的参数，出发点是一个样本出现的概率是与 $f(x)$ 相关的，同时不考虑非线性，只考虑线性关系 $Wx$ ，假设说有隐变量，那么隐变量也通过线性关系合并 $Wx+Wv$ ，得到上述结果。

从玻尔兹曼机的代码来看，他的训练过程是：给定输入，估计概率进行采样，然后反估计概率及采样，然后再估计概率及采样。但是直接看代码会想不明白里面的参数更新公式。他的参数更新公式是需要数学理论推导的。数学理论的出发点就是样本出现的概率是与 $f(x)$ 相关的。这个出发点其实就是极大似然估计，什么模型的出发点是最小均方误差？

参考：[受限玻尔兹曼机（RBM）原理总结](https://www.cnblogs.com/pinard/p/6530523.html)


















# 备注
记录看书过程中的灵感